{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5aa141-24ae-4d82-a02c-65a0e124712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install all the packages\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebefbc8-796d-4f6c-963d-1b7d5224e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707e7b93-6977-4670-9d61-1b00a60406ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by naming the features\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70bc1891-83ff-4a1b-add4-639baf400f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset through pandas function\n",
    "iris_data = pd.read_csv( url , names = names )\n",
    "print(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa2821f5-90b1-4e10-b3d4-694eec8a9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal-length  150 non-null    float64\n",
      " 1   sepal-width   150 non-null    float64\n",
      " 2   petal-length  150 non-null    float64\n",
      " 3   petal-width   150 non-null    float64\n",
      " 4   Class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the table \n",
    "iris_data_analyze = iris_data.info()\n",
    "print(iris_data_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0191fac1-3bbb-4ec0-b235-0672328c4b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal-length    0\n",
      "sepal-width     0\n",
      "petal-length    0\n",
      "petal-width     0\n",
      "Class           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values \n",
    "missing_values = iris_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb49d4d-06c2-44d1-b27b-486cee5f189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the inputs with feature variables\n",
    "inputs = iris_data.drop(columns = ['Class'])\n",
    "# Assigning the outputs with targret variables \n",
    "outputs = iris_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f27295f-a699-48aa-9653-98f3131e8ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the top section of inputs \n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "490a5617-12b7-4263-8910-63d74038dc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the top section of outputs \n",
    "outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7968c2e-031c-4998-aeba-d175ed19c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into one dimensinol numpy array using numpy \n",
    "outputs_1d = outputs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65664783-0b0f-4d85-a203-4761e21088f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Converting non-numerical values into numerical values using LabelEncoder\n",
    "# Outputs(target variables) data structure is object type\n",
    "le = preprocessing.LabelEncoder()\n",
    "outputs_encoded = le.fit_transform(outputs_1d)\n",
    "# Displaying the converted values \n",
    "print(outputs_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e702878-4207-483a-800d-2f7d1d22ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataset for training(80%) and testing(20%)\n",
    "inputs_train, inputs_test, outputs_encoded_train, outputs_encoded_test = train_test_split(inputs, outputs_encoded, test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df055942-ec21-438f-a77d-c7e3584168f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the inputs data for both training and testing \n",
    "# Target variables are not normalized\n",
    "# For Normalization we are using standardization(Z-score normalization) \n",
    "# Initialing the scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Scalering the inputs data (features variables) of training \n",
    "inputs_train_normalized = scaler.fit_transform(inputs_train)\n",
    "# Scalering the inputs data (features variables) of testing \n",
    "inputs_test_normalized = scaler.fit_transform(inputs_test)\n",
    "# Displaying the size of Normalized data for training\n",
    "print(inputs_train_normalized.size)\n",
    "# Displaying the size of Normalized data for testing\n",
    "print(inputs_test_normalized.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4962e-c938-442e-b142-d19aea664550",
   "metadata": {},
   "source": [
    "In feature variables there are 150 rows and 4 columns. So the total number of inputs data are 600(150*4). Therefore, training inputs = 480 (600 * 0.8) and testing inputs = 120 (600 * 0.2). Target variables are not normalized. After normalization, the data structure is always converted to numpy array. So, while using pytorch we need to convert the data structure in pytorch tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d8b84a4-437d-45ab-aea7-ea2cc0b83341",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert the dataset to PyTorch tensors\n",
    "c_inputs_train_normalized = torch.tensor(inputs_train_normalized, dtype=torch.float32)\n",
    "c_inputs_test_normalized = torch.tensor(inputs_test_normalized, dtype=torch.float32)\n",
    "c_outputs_encoded_train = torch.tensor(outputs_encoded_train, dtype=torch.long)\n",
    "c_outputs_encoded_test = torch.tensor(outputs_encoded_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd631d5d-925d-48f7-9142-9b302ae7afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing MLP model\n",
    "# Constructor : initializing \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer1, hidden_layer2, hidden_layer3, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "    \n",
    "        # Designing the layer  \n",
    "        self.input_hidden1_layer = nn.Linear(input_size, hidden_layer1)\n",
    "        self.hidden1_hidden2_layer = nn.Linear(hidden_layer1, hidden_layer2)\n",
    "        self.hidden2_hidden3_layer = nn.Linear(hidden_layer2, hidden_layer3)\n",
    "        self.hidden3_output_layer = nn.Linear(hidden_layer3, output_size)\n",
    "        # Defining the Activation Function: using rectified linear unit\n",
    "        self.activation_function = nn.ReLU()\n",
    "\n",
    "    # Passing the inputs into forward direction and computing\n",
    "    def feedforwarding(self, inputs):\n",
    "        computed_first_conn = self.input_hidden1_layer(inputs)\n",
    "        computed_first_conn_with_activation = self.activation_function(computed_first_conn)\n",
    "        computed_second_conn = self.hidden1_hidden2_layer(computed_first_conn_with_activation)\n",
    "        computed_second_conn_with_activation = self.activation_function(computed_second_conn)\n",
    "        computed_third_conn = self.hidden2_hidden3_layer(computed_second_conn_with_activation)\n",
    "        computed_third_conn_with_activation = self.activation_function(computed_third_conn)\n",
    "        computed_outputs = self.hidden3_output_layer(computed_third_conn_with_activation)\n",
    "        return computed_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b376136b-0aaa-4824-b34c-d38cfb13ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model, initialing\n",
    "# inputs size will number of features\n",
    "# Three hidden layer with 14,7,3 nodes\n",
    "# output_size wii be one\n",
    "# For evaluation purpose with other model this values are used\n",
    "input_size = c_inputs_train_normalized.shape[1] # counting the number of features\n",
    "hidden_layer1 = 14\n",
    "hidden_layer2 = 7\n",
    "hidden_layer3 = 3\n",
    "output_size = 3\n",
    "model = MLP(input_size, hidden_layer1, hidden_layer2, hidden_layer3, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76aa26f6-e2f9-45cc-930f-5c21c10e88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Defining the optimizer: LBFGS Ooptimizer is used\n",
    "optimizer = optim.LBFGS(model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cccc7d34-535a-4aa4-867b-5af5d72ef072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.1000912189483643\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "def closure():\n",
    "    # set to training mode\n",
    "    model.train()\n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward feeding \n",
    "    outputs = model.feedforwarding(c_inputs_train_normalized)\n",
    "    # calculating the loss\n",
    "    loss = criterion(outputs, c_outputs_encoded_train)\n",
    "    # Backward chaining \n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# Perform LBFGS optimization step: \n",
    "# LBFGS optimizer has its own looping rules\n",
    "# So we don't need to perform the iteration\n",
    "loss = optimizer.step(closure)\n",
    "print(f'loss : {loss}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8223df7-6a3b-4b07-b374-9533552ddaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.2333\n"
     ]
    }
   ],
   "source": [
    "# Testing the model with test dataset\n",
    "# set to testing mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model.feedforwarding(c_inputs_test_normalized)\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "    accuracy = (predicted == c_outputs_encoded_test).sum().item() / c_outputs_encoded_test.size(0)\n",
    "    print(f'Accuracy on test data: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26966f6d-5244-4f95-9b33-7f39db630bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ad0c6-f88d-4df3-9db3-e45a3fac3e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
