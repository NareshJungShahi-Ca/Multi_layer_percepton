{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "090b6925-eaeb-4b9e-a460-750f7c0c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16044c6b-4653-4be0-9226-d6e5c54635c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe78c015-cbed-4f9d-9cf2-ef3316af7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by naming the features\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab18f166-8da9-400b-a21a-b93c07781322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           Class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset through pandas function\n",
    "iris_data = pd.read_csv( url , names = names )\n",
    "print(iris_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87c4cb85-7c49-47ee-83f1-74845211dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal-length  150 non-null    float64\n",
      " 1   sepal-width   150 non-null    float64\n",
      " 2   petal-length  150 non-null    float64\n",
      " 3   petal-width   150 non-null    float64\n",
      " 4   Class         150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the table \n",
    "iris_data_analyze = iris_data.info()\n",
    "print(iris_data_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "997d46ce-3427-461c-a5d4-6eb0a361962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal-length    0\n",
      "sepal-width     0\n",
      "petal-length    0\n",
      "petal-width     0\n",
      "Class           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values \n",
    "missing_values = iris_data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13801fb6-5897-4155-86ee-9fc4754f486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the inputs with feature variables\n",
    "inputs = iris_data.drop(columns = ['Class'])\n",
    "# Assigning the outputs with targret variables \n",
    "outputs = iris_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c22fc89-70cc-4574-9032-8e32445f9b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the top section of inputs \n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04976588-d299-440e-9130-59ce0fd94bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the top section of outputs \n",
    "outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ffc69cdd-9a7b-42e0-94f6-bdeaad306a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into one dimensinol numpy array using numpy \n",
    "outputs_1d = outputs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "383cb3fd-d09c-4bbd-a2c7-7e4310874064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Converting non-numerical values into numerical values using LabelEncoder\n",
    "# Outputs(target variables) data structure is object type\n",
    "le = preprocessing.LabelEncoder()\n",
    "outputs_encoded = le.fit_transform(outputs_1d)\n",
    "# Displaying the converted values \n",
    "print(outputs_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b391f5b-8700-4400-b825-2fba27d823d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataset for training(80%) and testing(20%)\n",
    "inputs_train, inputs_test, outputs_encoded_train, outputs_encoded_test = train_test_split(inputs, outputs_encoded, test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb1c9576-abf7-4c61-a938-efd062d9b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the inputs data for both training and testing \n",
    "# Target variables are not normalized\n",
    "# For Normalization we are using standardization(Z-score normalization) \n",
    "# Initialing the scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Scalering the inputs data (features variables) of training \n",
    "inputs_train_normalized = scaler.fit_transform(inputs_train)\n",
    "# Scalering the inputs data (features variables) of testing \n",
    "inputs_test_normalized = scaler.fit_transform(inputs_test)\n",
    "# Displaying the size of Normalized data for training\n",
    "print(inputs_train_normalized.size)\n",
    "# Displaying the size of Normalized data for testing\n",
    "print(inputs_test_normalized.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "092f793a-5289-48c0-87e1-34940715dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Activation function: we are using Sigmoid \n",
    "\n",
    "# Define the Sigmoid activation function\n",
    "def sigmoid(inputs):\n",
    "    inputs = np.clip(inputs, -500, 500)  # Clipping the input range\n",
    "    return 1 / (1 + np.exp(-inputs))\n",
    "\n",
    "# Define the derivative of Sigmoid for backpropagation\n",
    "def sigmoid_derivative(inputs):\n",
    "    inputs = np.clip(inputs, -500, 500)  # Clipping the input range\n",
    "    return inputs * (1 - inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3b12e3f-e4ca-4d47-a44e-bdb4988de24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing the MLP model\n",
    "# Our MLP model will consist of three hidden layers\n",
    "class MLP():\n",
    "    def __init__(self, input_size, h1_ly_size, h2_ly_size, h3_ly_size, output_size):\n",
    "        \n",
    "        # Designing the layer \n",
    "        # Initialize weights and biases for input to hidden layer 1\n",
    "        self.wt_input_h1_size = np.random.randn(input_size, h1_ly_size)\n",
    "        self.bais_h1 = np.zeros((1, h1_ly_size))\n",
    "\n",
    "        # Initialize weights and biases for hidden layer 1 to hidden layer 2\n",
    "        self.wt_h1_h2_size = np.random.randn(h1_ly_size, h2_ly_size)\n",
    "        self.bais_h2 = np.zeros((1, h2_ly_size))\n",
    "\n",
    "        \n",
    "        # Initialize weights and biases for hidden layer 2 to hidden layer 3\n",
    "        self.wt_h2_h3_size = np.random.randn(h2_ly_size, h3_ly_size)\n",
    "        self.bais_h3 = np.zeros((1, h3_ly_size))\n",
    "\n",
    "        # Initialize weights and biases for hidden layer 3 to output layer\n",
    "        self.wt_h3_output_size = np.random.randn(h3_ly_size, output_size)\n",
    "        self.bais_outputs = np.zeros((1, output_size))\n",
    "        \n",
    "    # Calculation method for forward chaining \n",
    "    def forwardfeeding(self, input):\n",
    "        # Calculating the h1 layer by passing inputs\n",
    "        self.computed_h1 = np.dot(input, self.wt_input_h1_size) + self.bais_h1\n",
    "        self.h1_outputs = sigmoid(self.computed_h1)\n",
    "\n",
    "        # Calculating the h2 layer by passing h1 layer inputs\n",
    "        self.computed_h2 = self.h1_outputs.dot(self.wt_h1_h2_size) + self.bais_h2 \n",
    "        self.h2_outputs = sigmoid(self.computed_h2)\n",
    "        \n",
    "        # Calculating the h3 layer by passing h2 layer inputs\n",
    "        self.computed_h3 = np.dot(self.h2_outputs, self.wt_h2_h3_size) + self.bais_h3\n",
    "        self.h3_outputs = sigmoid(self.computed_h3)\n",
    "        \n",
    "         # Calculating the output layer by passing h3 layer inputs\n",
    "        self.computed_output= np.dot(self.h3_outputs, self.wt_h3_output_size) + self.bais_outputs\n",
    "        output = sigmoid(self.computed_output)\n",
    "\n",
    "        return output\n",
    "        \n",
    "    # Calculation method for backward chaining and loss\n",
    "    def backwardfeeding(self, input, output, fw_output, learning_rate):\n",
    "\n",
    "        # Converting the dimension\n",
    "        reshape_output = output.reshape(output.size,1)    \n",
    "        \n",
    "        # Calculate the error in the output\n",
    "        output_error = fw_output - reshape_output\n",
    "\n",
    "        # Calculate the error, delta weights and delta bais for hidden layer 3\n",
    "        d_weights3 = self.h3_outputs.T.dot(output_error * sigmoid_derivative(self.computed_output))\n",
    "        d_bias3 = np.sum(output_error * sigmoid_derivative(self.computed_output), axis=0, keepdims=True)\n",
    "        error_hidden_h3 = output_error.dot(self.wt_h3_output_size.T) * sigmoid_derivative(self.computed_h3)\n",
    "\n",
    "        # Calculate the error, delta weights and delta bais for hidden layer 2\n",
    "        d_weights2 = self.h2_outputs.T.dot(error_hidden_h3 * sigmoid_derivative(self.computed_h3))\n",
    "        d_bias2 = np.sum(error_hidden_h3 * sigmoid_derivative(self.computed_h3), axis=0, keepdims=True)\n",
    "        error_hidden_h2 = error_hidden_h3.dot(self.wt_h2_h3_size.T) * sigmoid_derivative(self.computed_h2)\n",
    "\n",
    "        # Calculate the error, delta weights and delta bais for hidden layer 1\n",
    "        d_weights1 = self.h1_outputs.T.dot(error_hidden_h2 * sigmoid_derivative(self.computed_h2))\n",
    "        d_bias1 = np.sum(error_hidden_h2 * sigmoid_derivative(self.computed_h2), axis=0, keepdims=True)\n",
    "        error_hidden_h1 = error_hidden_h2.dot(self.wt_h1_h2_size.T) * sigmoid_derivative(self.computed_h1)\n",
    "        \n",
    "        # Calculate the delta weights and delta bais for input \n",
    "        d_weights = input.T.dot(error_hidden_h1)\n",
    "        d_bias = np.sum(error_hidden_h1, axis=0, keepdims=True)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.wt_h3_output_size -= learning_rate * d_weights3\n",
    "        self.bais_outputs -= learning_rate * d_bias3\n",
    "        self.wt_h2_h3_size -= learning_rate * d_weights2\n",
    "        self.bais_h3 -= learning_rate * d_bias2\n",
    "        self.wt_h1_h2_size -= learning_rate * d_weights1\n",
    "        self.bais_h2 -= learning_rate * d_bias1\n",
    "        self.wt_input_h1_size -= learning_rate * d_weights\n",
    "        self.bais_h1 -= learning_rate * d_bias\n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d2f5fad-5469-46b3-acda-6c427299a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training method\n",
    "def training_MLP(model, input, output, iteration, learning_rate):\n",
    "    for iteration in range(iteration):\n",
    "        # Forward passing \n",
    "        fw_output = model.forwardfeeding(input)\n",
    "        # Backward passing and updating weights and bais\n",
    "        model.backwardfeeding(input, output, fw_output, learning_rate)\n",
    "\n",
    "        if (iteration+1) % 100 == 0:\n",
    "            loss = np.mean((output.reshape(output.size,1)- fw_output) ** 2)\n",
    "            print(f'iteration {iteration+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd12af5b-2855-431b-b7e4-f55463f49db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this model, initialing\n",
    "# inputs size will number of features\n",
    "# Three hidden layer with 14,7,3 nodes\n",
    "# output_size wii be one\n",
    "# For evaluation purpose with other model this values are used\n",
    "input_size = inputs_train_normalized.shape[1] # counting the number of features\n",
    "hidden_layer1 = 14\n",
    "hidden_layer2 = 7\n",
    "hidden_layer3 = 3\n",
    "output_size = 3\n",
    "model = MLP(input_size, hidden_layer1, hidden_layer2, hidden_layer3, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98eee767-dcfb-4f88-8e72-bead0fefceda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100, Loss: 1.3446\n"
     ]
    }
   ],
   "source": [
    "# Training the model \n",
    "# Call the method\n",
    "training_MLP(model, inputs_train_normalized, outputs_encoded_train, 100, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1987bd33-53a9-4abd-95f6-ce801aef7399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]\n",
      " [7.12457641e-218 7.12457641e-218 7.31058579e-001]]\n",
      "30\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained MLP with test data \n",
    "predicted_outputs = model.forwardfeeding(inputs_test_normalized)\n",
    "print(predicted_outputs)\n",
    "\n",
    "# Binary predictions for classification\n",
    "binary_predicted_outputs = np.round(predicted_outputs)\n",
    "\n",
    "print(binary_predicted_outputs.shape[0])\n",
    "print(binary_predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ba6e18c-2ff5-4fe6-ae96-3eeecd3ba0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "# Compute accuracy (percentage of correct predictions)\n",
    "accuracy = np.mean(binary_predicted_outputs == outputs_encoded_test.reshape(outputs_encoded_test.size,1))\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5cfef-3c1d-4489-84a8-5c06fd41cb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
